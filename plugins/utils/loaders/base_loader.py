# plugins/utils/loaders/base_loader.py
from pathlib import Path
import duckdb
import pandas as pd
import logging
import json
from plugins.config import constants as C

log = logging.getLogger(__name__)

def read_parquet_dir(base_path: Path, pattern: str = "*.parquet", union_by_name: bool = True) -> pd.DataFrame:
    """ğŸ“¦ ì§€ì • ê²½ë¡œì˜ parquet ë°ì´í„°ë¥¼ DuckDBë¡œ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜"""
    if not base_path.exists():
        raise FileNotFoundError(f"âŒ Directory not found: {base_path}")
    files = list(base_path.rglob(pattern))
    if not files:
        raise FileNotFoundError(f"âŒ No {pattern} files found in {base_path}")

    conn = duckdb.connect(database=":memory:")
    query = f"SELECT * FROM read_parquet('{base_path}/{pattern}', union_by_name={str(union_by_name).lower()})"
    df = conn.execute(query).df()
    conn.close()

    log.info(f"ğŸ“Š Loaded {len(df):,} rows from {base_path}")
    return df


def read_json_dir(base_path: Path, pattern: str = "*.json") -> pd.DataFrame:
    """ğŸ“¦ ì§€ì • ê²½ë¡œì˜ JSON ë°ì´í„°ë¥¼ ìë™ ìŠ¤í‚¤ë§ˆë¡œ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜"""
    if not base_path.exists():
        raise FileNotFoundError(f"âŒ Directory not found: {base_path}")
    files = list(base_path.rglob(pattern))
    if not files:
        raise FileNotFoundError(f"âŒ No JSON files found in {base_path}")

    conn = duckdb.connect(database=":memory:")
    query = f"SELECT * FROM read_json_auto('{base_path}/{pattern}')"
    df = conn.execute(query).df()
    conn.close()

    log.info(f"ğŸ“Š Loaded {len(df):,} JSON rows from {base_path}")
    return df


def latest_partition(base_dir: Path) -> Path:
    print("ğŸ” DEBUG base_dir:", base_dir, type(base_dir))
    candidates = sorted(base_dir.glob("trd_dt=*"), reverse=True)
    print("ğŸ” DEBUG candidates:", candidates)
    if not candidates:
        raise FileNotFoundError(f"âŒ No partitions under {base_dir}")
    latest = candidates[0]
    log.warning(f"âš ï¸ Using latest snapshot: {latest.name}")
    return latest



def resolve_snapshot_date(domain: str, fallback_dir: Path | None = None) -> str:
    """
    âœ… domain ê¸°ì¤€ìœ¼ë¡œ latest_snapshot_meta.jsonì—ì„œ ìµœì‹  snapshot ì¼ìë¥¼ ë°˜í™˜
    - íŒŒì¼ì´ ì—†ê±°ë‚˜ domainì´ ì—†ìœ¼ë©´ fallback_dirì—ì„œ ìµœì‹  íŒŒí‹°ì…˜ íƒìƒ‰
    """
    meta_path = getattr(C, "LATEST_SNAPSHOT_META_PATH", None)
    if meta_path and meta_path.exists():
        try:
            with open(meta_path, "r", encoding="utf-8") as f:
                meta = json.load(f)
            if domain in meta:
                return meta[domain]["latest_trd_dt"]
        except Exception as e:
            log.warning(f"âš ï¸ Failed to read latest_snapshot_meta.json: {e}")

    # fallback: í´ë” ë‚´ ìµœì‹  trd_dt íŒŒí‹°ì…˜ ê²€ìƒ‰
    if fallback_dir and fallback_dir.exists():
        latest_dir = latest_partition(fallback_dir)
        return latest_dir.name.split("=")[-1]

    raise FileNotFoundError(f"âŒ Cannot resolve snapshot date for domain={domain}")