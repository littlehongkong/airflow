# plugins/utils/loaders/base_loader.py
from pathlib import Path
import duckdb
import pandas as pd
import logging

log = logging.getLogger(__name__)

def read_parquet_dir(base_path: Path, pattern: str = "*.parquet", union_by_name: bool = True) -> pd.DataFrame:
    """ğŸ“¦ ì§€ì • ê²½ë¡œì˜ parquet ë°ì´í„°ë¥¼ DuckDBë¡œ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜"""
    if not base_path.exists():
        raise FileNotFoundError(f"âŒ Directory not found: {base_path}")
    files = list(base_path.rglob(pattern))
    if not files:
        raise FileNotFoundError(f"âŒ No {pattern} files found in {base_path}")

    conn = duckdb.connect(database=":memory:")
    query = f"SELECT * FROM read_parquet('{base_path}/{pattern}', union_by_name={str(union_by_name).lower()})"
    df = conn.execute(query).df()
    conn.close()

    log.info(f"ğŸ“Š Loaded {len(df):,} rows from {base_path}")
    return df


def read_json_dir(base_path: Path, pattern: str = "*.json") -> pd.DataFrame:
    """ğŸ“¦ ì§€ì • ê²½ë¡œì˜ JSON ë°ì´í„°ë¥¼ ìë™ ìŠ¤í‚¤ë§ˆë¡œ ì½ì–´ DataFrameìœ¼ë¡œ ë°˜í™˜"""
    if not base_path.exists():
        raise FileNotFoundError(f"âŒ Directory not found: {base_path}")
    files = list(base_path.rglob(pattern))
    if not files:
        raise FileNotFoundError(f"âŒ No JSON files found in {base_path}")

    conn = duckdb.connect(database=":memory:")
    query = f"SELECT * FROM read_json_auto('{base_path}/{pattern}')"
    df = conn.execute(query).df()
    conn.close()

    log.info(f"ğŸ“Š Loaded {len(df):,} JSON rows from {base_path}")
    return df


def latest_partition(base_dir: Path) -> Path:
    """ğŸ“‚ ê°€ì¥ ìµœì‹  trd_dt íŒŒí‹°ì…˜ì„ ë°˜í™˜"""
    candidates = sorted(base_dir.glob("trd_dt=*"), reverse=True)
    if not candidates:
        raise FileNotFoundError(f"âŒ No partitions under {base_dir}")
    latest = candidates[0]
    log.warning(f"âš ï¸ Using latest snapshot: {latest.name}")
    return latest
