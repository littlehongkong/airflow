# plugins/utils/loaders/equity/symbol_loader.py
import pandas as pd
import logging
import re
from datetime import datetime
from pathlib import Path

from plugins.config.constants import DATA_LAKE_VALIDATED
from plugins.utils.loaders.base_loader import read_parquet_dir

log = logging.getLogger(__name__)


def find_latest_partition_before(base_dir: Path, target_date: str) -> Path:
    """
    âœ… ì£¼ì–´ì§„ trd_dt ì´í•˜ ì¤‘ ê°€ì¥ ìµœì‹  íŒŒí‹°ì…˜ ë°˜í™˜
    - base_dir/trd_dt=YYYY-MM-DD êµ¬ì¡° ê°€ì •
    - target_date ì´í›„ì˜ í´ë”ëŠ” ë¬´ì‹œí•˜ê³ , ê·¸ ì´ì „ ì¤‘ ê°€ì¥ ìµœê·¼ ë‚ ì§œ ë°˜í™˜
    """
    target = datetime.fromisoformat(target_date)
    candidates = []

    if not base_dir.exists():
        raise FileNotFoundError(f"âŒ Directory not found: {base_dir}")

    for d in base_dir.glob("trd_dt=*"):
        match = re.search(r"trd_dt=(\d{4}-\d{2}-\d{2})", d.name)
        if not match:
            continue
        part_date = datetime.fromisoformat(match.group(1))
        if part_date <= target:
            candidates.append((part_date, d))

    if not candidates:
        raise FileNotFoundError(f"âŒ No partitions before {target_date} in {base_dir}")

    # ë‚ ì§œ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬ í›„ ì²« ë²ˆì§¸ ì„ íƒ
    latest_path = sorted(candidates, key=lambda x: x[0], reverse=True)[0][1]
    log.warning(f"âš ï¸ Using fallback symbol_list partition: {latest_path.name}")
    return latest_path


def load_symbol_list(
    domain_group: str,
    vendor: str,
    exchange_codes: list[str],
    trd_dt: str,
    include_types: list[str] | None = None,
    exclude_field: str | None = None,
    exclude_values: list[str] | None = None,
) -> pd.DataFrame:
    """
    âœ… Symbol List ë¡œë” (ETF í¬í•¨)
    - ê±°ë˜ì†Œë³„ symbol_list parquet ë³‘í•©
    - type í•„í„°ë§ ì§€ì› (ì˜ˆ: ["ETF"], ["Common Stock"])
    - âš™ï¸ trd_dt ë°ì´í„°ê°€ ì—†ì„ ê²½ìš° ê°€ì¥ ìµœê·¼ íŒŒí‹°ì…˜ fallback
    """
    dfs = []

    for ex in exchange_codes:
        base_dir = (
            DATA_LAKE_VALIDATED
            / domain_group
            / "symbol_list"
            / f"vendor={vendor}"
            / f"exchange_code={ex}"
        )
        base_path = base_dir / f"trd_dt={trd_dt}"

        try:
            if not base_path.exists():
                log.warning(f"âš ï¸ symbol_list for {trd_dt} not found at {base_path}, finding latest available...")
                base_path = find_latest_partition_before(base_dir, trd_dt)

            log.info(f"ğŸ“¦ Loading symbol_list from: {base_path}")
            df = read_parquet_dir(base_path)
            df["exchange_code"] = ex
            dfs.append(df)

        except FileNotFoundError as e:
            log.warning(f"âš ï¸ No symbol_list found for exchange_code={ex}: {e}")
            continue

    if not dfs:
        raise FileNotFoundError(f"âŒ No valid symbol_list data for exchanges={exchange_codes}")

    final_df = pd.concat(dfs, ignore_index=True)

    # âœ… type í•„í„°ë§
    if include_types:
        before = len(final_df)
        final_df = final_df[final_df["type"].isin(include_types)]
        log.info(f"ğŸ“Š Filtered symbol_list by type={include_types} ({before:,}â†’{len(final_df):,})")

    # âœ… íŠ¹ì • í•„ë“œ ê°’ ì œì™¸
    if exclude_field and exclude_values:
        if exclude_field in final_df.columns:
            before_rows = len(final_df)
            final_df = final_df[~final_df[exclude_field].isin(exclude_values)]
            after_rows = len(final_df)
            log.info(
                f"ğŸš« Excluded rows where {exclude_field} in {exclude_values} "
                f"({before_rows - after_rows:,} removed, remaining={after_rows:,})"
            )
        else:
            log.warning(f"âš ï¸ Exclude field '{exclude_field}' not found in DataFrame columns.")

    return final_df
