# plugins/utils/loaders/equity/fundamentals_loader.py
import pandas as pd
from plugins.config.constants import DATA_LAKE_VALIDATED
from plugins.utils.loaders.base_loader import read_parquet_dir, read_json_dir


import logging as log


def load_fundamentals_raw(domain_group: str, vendor: str, exchange_code: str, trd_dt: str) -> pd.DataFrame:
    """
    âœ… Fundamentals Raw Loader
    - ê±°ë˜ì†Œë³„ ì¢…ëª©ë‹¨ìœ„ JSON ë°ì´í„° ë¡œë“œ
    - validator ë˜ëŠ” ì „ì²˜ë¦¬ìš©
    ê²½ë¡œ ì˜ˆì‹œ:
    /data_lake/validated/equity/fundamentals/vendor=eodhd/exchange_code=KO/trd_dt=2025-11-05/000500.json
    """
    base_path = (
        DATA_LAKE_VALIDATED
        / domain_group
        / "fundamentals"
        / f"vendor={vendor}"
        / f"exchange_code={exchange_code}"
        / f"trd_dt={trd_dt}"
    )

    if not base_path.exists():
        raise FileNotFoundError(f"âŒ Directory not found: {base_path}")

    # JSONL or multi-JSON structure â†’ DuckDB auto detection
    try:
        df = read_json_dir(base_path, "*.json")
    except Exception as e:
        raise RuntimeError(f"âš ï¸ Failed to read fundamentals raw JSON: {e}")

    df["exchange_code"] = exchange_code
    df["trd_dt"] = trd_dt

    log.info(f"ğŸ“¦ Loaded {len(df):,} raw fundamentals rows from {base_path}")
    return df


def load_fundamentals_latest(domain_group: str, vendor: str, exchange_codes: list[str]) -> pd.DataFrame:
    """
    âœ… Fundamentals Latest Loader
    - fundamentals_general_latest.parquet ê¸°ë°˜ (ìš”ì•½ë³¸)
    - AssetMaster, Snapshot ìƒì„± ì‹œ ì‚¬ìš©
    """
    dfs = []
    for ex in exchange_codes:
        path = (
            DATA_LAKE_VALIDATED
            / domain_group
            / "fundamentals"
            / f"vendor={vendor}"
            / f"exchange_code={ex}"
            / "fundamentals_general_latest.parquet"
        )

        if not path.exists():
            log.warning(f"âš ï¸ Missing fundamentals_general_latest.parquet for {ex}")
            continue

        try:
            df = read_parquet_dir(path.parent, "fundamentals_general_latest.parquet")
            df["exchange_code"] = ex
            dfs.append(df)
        except Exception as e:
            log.warning(f"âš ï¸ Failed to load fundamentals for {ex}: {e}")
            continue

    if not dfs:
        log.warning("âš ï¸ No fundamentals_general_latest files found")
        raise FileNotFoundError("No valid fundamentals_general_latest data for exchanges={exchange_codes}")

    final_df = pd.concat(dfs, ignore_index=True)
    log.info(f"ğŸ“Š Loaded {len(final_df):,} rows from fundamentals_general_latest")
    return final_df
