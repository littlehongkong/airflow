from airflow.providers.postgres.hooks.postgres import PostgresHook
from datetime import datetime
import traceback
import json

def run_and_log(func, postgres_conn_id, dag_id, task_id, airflow_context=None, **kwargs):
    """
    ê³µí†µ ì‹¤í–‰ ë° ë¡œê·¸ ì ì¬ ìœ í‹¸ë¦¬í‹°
    - func: ì‹¤í–‰í•  íŒŒì´í”„ë¼ì¸ ë©”ì„œë“œ (fetch_and_load ë“±)
    - dag_id, task_id: Airflow Contextì—ì„œ ì „ë‹¬
    - postgres_conn_id: Airflow Connection ID
    """

    pg_hook = PostgresHook(postgres_conn_id=postgres_conn_id)

    # âœ… ë¡œê·¸ í…Œì´ë¸” ë³´ì¥
    create_sql = """
    CREATE TABLE IF NOT EXISTS pipeline_task_log (
        id SERIAL PRIMARY KEY,
        dag_id TEXT,
        task_id TEXT,
        run_time TIMESTAMP,
        status TEXT,
        result_info JSONB,
        error_message TEXT
    );
    """
    pg_hook.run(create_sql)

    # âœ… op_kwargsë§Œ ì¶”ì¶œ (Airflow context ì œì™¸)
    op_kwargs = kwargs.get("op_kwargs", {}) if isinstance(kwargs.get("op_kwargs"), dict) else kwargs

    result_info = {}
    status = "SUCCESS"
    error_message = None
    layer = kwargs.get("layer")

    assert layer is not None, 'ë¡œê·¸í…Œì´ë¸”ì— ì ì¬í•  layer ì •ë³´ë¥¼ ê¸°ì…í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'

    try:
        # ì‹¤ì œ task í•¨ìˆ˜ ì‹¤í–‰
        result = func(context=airflow_context, **op_kwargs)

        # âœ… ê²°ê³¼ ì •ë¦¬: op_kwargs + ê³µí†µ í•„ë“œë§Œ
        result_info = {
            **op_kwargs,
            "status": "success",
            "record_count": result.get("record_count"),
            "validated_path": result.get("validated_path"),
        }

        # ê¸°ë³¸ê°’ ì±„ìš°ê¸°
        if "record_count" not in result_info:
            result_info["record_count"] = None

        # âœ… ì„±ê³µ ì‹œ ë¡œê·¸ ë‚¨ê¸°ê¸°
        _insert_pipeline_log(pg_hook, dag_id, task_id, status, result_info, error_message, layer)
        print(f"ğŸ“˜ ë¡œê·¸ ì €ì¥ ì™„ë£Œ [SUCCESS] - {result_info}")


    except Exception as e:
        status = "FAILED"
        error_message = f"{type(e).__name__}: {str(e)}\n{traceback.format_exc()}"

        # ì‹¤íŒ¨í•œ ê²½ìš°ì—ë„ ì…ë ¥ê°’ ë¡œê·¸ ë‚¨ê¹€
        result_info = {**op_kwargs, "status": "failed"}

        # âœ… ë¡œê·¸ ë‚¨ê¸°ê³  ì¬-raise
        _insert_pipeline_log(pg_hook, dag_id, task_id, status, result_info, error_message, layer)
        print(f"ğŸ“˜ ë¡œê·¸ ì €ì¥ ì™„ë£Œ [FAILED] - {result_info}")

        raise

# psql -U postgres -d postgres

    return result_info

def _insert_pipeline_log(pg_hook, dag_id, task_id, status, result_info, error_message, layer: str = 'lake'):
    """ê³µí†µ ë¡œê·¸ insert í•¨ìˆ˜"""
    insert_sql = """
        INSERT INTO pipeline_task_log(dag_id, task_id, run_time, status, result_info, error_message, layer)
        VALUES (%s, %s, %s, %s, %s, %s, %s)
    """
    pg_hook.run(
        insert_sql,
        parameters=(dag_id, task_id, datetime.utcnow(), status, json.dumps(result_info, ensure_ascii=False),
                    error_message, layer),
    )