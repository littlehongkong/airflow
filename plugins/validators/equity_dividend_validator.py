# plugins/validators/dividend_validator.py
import os
import json
import tempfile
import pandas as pd
import pandera.pandas as pa
from pandera import Column, Check
from plugins.validators.base_validator import BaseDataValidator
from soda.scan import Scan
import yaml
import numpy as np


class EquityDividendValidator(BaseDataValidator):
    """ê±°ë˜ì†Œë³„ ë°°ë‹¹(Dividends) ë°ì´í„° ê²€ì¦ Validator"""

    def __init__(self, exchange_code: str, trd_dt: str, data_domain: str = "dividends"):
        super().__init__(exchange_code, trd_dt, data_domain)
        self.schema = self._get_schema()

    # ============================================================
    # 1ï¸âƒ£ Pandera ìŠ¤í‚¤ë§ˆ ì •ì˜
    # ============================================================
    def _get_schema(self):
        return pa.DataFrameSchema(
            columns={
                "code": Column(
                    str,
                    nullable=False,
                    checks=[
                        Check(lambda s: s.str.len() > 0,
                              error="âŒ codeëŠ” ë¹ˆ ë¬¸ìì—´ì¼ ìˆ˜ ì—†ìŒ"),
                    ]
                ),
                "date": Column(
                    str,
                    nullable=False,
                    checks=[
                        Check(lambda s: s.str.match(r'^\d{4}-\d{2}-\d{2}$').all(),
                              error="âŒ date í˜•ì‹ ì˜¤ë¥˜ (YYYY-MM-DD í˜•ì‹ì´ì–´ì•¼ í•¨)"),
                        Check(lambda s: pd.to_datetime(s, errors='coerce').notna().all(),
                              error="âŒ dateê°€ ìœ íš¨í•œ ë‚ ì§œê°€ ì•„ë‹˜"),
                    ]
                ),
                "dividend": Column(
                    str,
                    nullable=False,
                    checks=[
                        Check(lambda s: s.str.match(r'^\d+(\.\d+)?$').all(),
                              error="âŒ dividend í˜•ì‹ ì˜¤ë¥˜ (ìˆ«ì í˜•ì‹ì´ì–´ì•¼ í•¨)"),
                        Check(lambda s: s.astype(float) > 0,
                              error="âŒ dividendëŠ” ì–‘ìˆ˜ì—¬ì•¼ í•¨"),
                    ]
                ),
                "currency": Column(
                    str,
                    nullable=False,
                    checks=[
                        Check(lambda s: s.str.match(r'^[A-Z]{3}$').all(),
                              error="âŒ currency í˜•ì‹ ì˜¤ë¥˜ (3ìë¦¬ ëŒ€ë¬¸ì í†µí™” ì½”ë“œ)"),
                    ]
                ),
                "declarationDate": Column(
                    str,
                    nullable=True,
                    checks=[
                        Check(lambda s: s.isna() | s.str.match(r'^\d{4}-\d{2}-\d{2}$'),
                              error="âŒ declarationDate í˜•ì‹ ì˜¤ë¥˜ (YYYY-MM-DD ë˜ëŠ” null)"),
                    ]
                ),
                "recordDate": Column(
                    str,
                    nullable=True,
                    checks=[
                        Check(lambda s: s.isna() | s.str.match(r'^\d{4}-\d{2}-\d{2}$'),
                              error="âŒ recordDate í˜•ì‹ ì˜¤ë¥˜ (YYYY-MM-DD ë˜ëŠ” null)"),
                    ]
                ),
                "paymentDate": Column(
                    str,
                    nullable=True,
                    checks=[
                        Check(lambda s: s.isna() | s.str.match(r'^\d{4}-\d{2}-\d{2}$'),
                              error="âŒ paymentDate í˜•ì‹ ì˜¤ë¥˜ (YYYY-MM-DD ë˜ëŠ” null)"),
                    ]
                ),
                "period": Column(
                    str,
                    nullable=True,
                ),
                "unadjustedValue": Column(
                    str,
                    nullable=True,
                    checks=[
                        Check(lambda s: s.isna() | s.str.match(r'^\d+(\.\d+)?$'),
                              error="âŒ unadjustedValue í˜•ì‹ ì˜¤ë¥˜ (ìˆ«ì ë˜ëŠ” null)"),
                        Check(lambda s: s.isna() | (pd.to_numeric(s, errors='coerce') > 0),
                              error="âŒ unadjustedValueëŠ” ì–‘ìˆ˜ì—¬ì•¼ í•¨"),
                    ]
                ),
            },
            checks=[
                # DataFrame ë ˆë²¨ ê²€ì¦: code + date ì¡°í•© ì¤‘ë³µ ì²´í¬
                Check(lambda df: ~df.duplicated(subset=['code', 'date']).any(),
                      error="âŒ ì¤‘ë³µëœ (code, date) ì¡°í•©ì´ ì¡´ì¬í•¨"),


                # ë‚ ì§œ ìˆœì„œ ê²€ì¦: declarationDate <= recordDate
                Check(lambda df: (
                        df['declarationDate'].isna() |
                        df['recordDate'].isna() |
                        (pd.to_datetime(df['declarationDate'], errors='coerce') <=
                         pd.to_datetime(df['recordDate'], errors='coerce'))
                ).all(),
                      error="âŒ declarationDateê°€ recordDateë³´ë‹¤ ëŠ¦ìŒ"),

                # ë‚ ì§œ ìˆœì„œ ê²€ì¦: recordDate <= paymentDate
                Check(lambda df: (
                        df['recordDate'].isna() |
                        df['paymentDate'].isna() |
                        (pd.to_datetime(df['recordDate'], errors='coerce') <=
                         pd.to_datetime(df['paymentDate'], errors='coerce'))
                ).all(),
                      error="âŒ recordDateê°€ paymentDateë³´ë‹¤ ëŠ¦ìŒ"),

                # ë¯¸ë˜ ë‚ ì§œ ì²´í¬
                Check(lambda df: (pd.to_datetime(df['date']) <= pd.Timestamp.now()).all(),
                      error="âŒ ë¯¸ë˜ ë‚ ì§œê°€ í¬í•¨ë˜ì–´ ìˆìŒ"),

                # ë„ˆë¬´ ì˜¤ë˜ëœ ë‚ ì§œ ì²´í¬
                Check(lambda df: (pd.to_datetime(df['date']) >= pd.Timestamp('1900-01-01')).all(),
                      error="âŒ 1900ë…„ ì´ì „ ë‚ ì§œê°€ í¬í•¨ë˜ì–´ ìˆìŒ"),
            ],
            strict=False,  # ì¶”ê°€ ì»¬ëŸ¼ í—ˆìš©
            coerce=False,  # íƒ€ì… ê°•ì œ ë³€í™˜ ì•ˆ í•¨
        )

    # ============================================================
    # 2ï¸âƒ£ ì „ì²´ ê²€ì¦ ì‹¤í–‰
    # ============================================================
    def validate(self, **kwargs):
        raw_dir = self._get_lake_path("raw")
        files = [f for f in os.listdir(raw_dir) if f.endswith(".json") or f.endswith(".jsonl")]
        if not files:
            print(f"âš ï¸ ê²€ì¦ ëŒ€ìƒ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {raw_dir}")
            return

        all_records = []
        for file in files:
            path = os.path.join(raw_dir, file)
            with open(path, "r", encoding="utf-8") as f:
                try:
                    if file.endswith(".jsonl"):
                        all_records.extend([json.loads(line) for line in f if line.strip()])
                    else:
                        all_records.extend(json.load(f))
                except Exception as e:
                    print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file} | {e}")

        df = pd.DataFrame(all_records)
        if df.empty:
            raise AssertionError("âŒ ê²€ì¦í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # âœ… Pandera ìŠ¤í‚¤ë§ˆ ê²€ì¦
        try:
            self.schema.validate(df, lazy=True)
            print(f"âœ… Pandera ê²€ì¦ í†µê³¼ ({len(df)} records)")
        except pa.errors.SchemaErrors as e:
            print(f"âŒ Pandera ê²€ì¦ ì‹¤íŒ¨:")
            print(e.failure_cases)
            raise AssertionError(f"âŒ Pandera ê²€ì¦ ì‹¤íŒ¨: {e}")

        # âœ… Soda Core ê²€ì¦ ì‹¤í–‰
        temp_path = os.path.join(raw_dir, "_dividends_temp.parquet")
        df.to_parquet(temp_path, index=False)
        self._run_soda_on_parquet(temp_path, mode="dividends")

    # ============================================================
    # 3ï¸âƒ£ Soda ì‹¤í–‰ ë¡œì§
    # ============================================================
    def _run_soda_on_parquet(self, parquet_path: str, mode: str = "dividends"):
        base_dir = "/opt/airflow/plugins/soda/checks"
        soda_check_file = os.path.join(base_dir, f"dividends_checks.yml")

        if not os.path.exists(soda_check_file):
            print(f"âš ï¸ {soda_check_file} ì—†ìŒ â€” ê±´ë„ˆëœ€.")
            return

        tmp_config = {"data_source my_duckdb": {"type": "duckdb", "path": ":memory:"}}
        with tempfile.NamedTemporaryFile(mode="w", suffix=".yml", delete=False) as tmp_file:
            yaml.dump(tmp_config, tmp_file)
            tmp_config_path = tmp_file.name

        scan = Scan()
        scan.set_data_source_name("my_duckdb")
        scan.add_configuration_yaml_file(tmp_config_path)
        scan.add_sodacl_yaml_files(soda_check_file)
        scan._data_source_manager.get_data_source("my_duckdb").connection.execute(
            f"CREATE TABLE dividends AS SELECT * FROM read_parquet('{parquet_path}')"
        )

        exit_code = scan.execute()
        print(f"ğŸ§ª Soda Scan ì™„ë£Œ (exit_code={exit_code}, mode={mode})")
        if exit_code != 0:
            raise AssertionError(f"âŒ Soda ê²€ì¦ ì‹¤íŒ¨: exit_code={exit_code}, mode={mode}")

        os.unlink(tmp_config_path)