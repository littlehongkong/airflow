import os
import json
import pandas as pd
from datetime import datetime
from plugins.validators.base_validator import BaseDataValidator


class FundamentalValidator(BaseDataValidator):
    """
    ğŸ§¾ í€ë”ë©˜í„¸ ë°ì´í„° ê²€ì¦ê¸° (ETF ì „ìš©ë£° + ê²½ê³  ìƒì„¸ ë¡œê·¸)
    --------------------------------------------------------------
    âœ… Common Stock â†” ETF ë¶„ë¦¬ ê²€ì¦
    âœ… ETF: Soda YAML ê¸°ë°˜ í•µì‹¬ í•­ëª©ë§Œ í™•ì¸
    âœ… Common Stock: General + Financials êµ¬ì¡° ê²€ì¦
    âœ… ëª¨ë“  ê²½ê³  ì‚¬ìœ ë¥¼ Airflow ë¡œê·¸ì— ì§ì ‘ ì¶œë ¥
    """

    def __init__(self, exchange_code: str, trd_dt: str, data_domain: str = "fundamentals", **kwargs):
        super().__init__(exchange_code, trd_dt, data_domain, **kwargs)
        self.required_general_fields = ["Code", "Type", "Name"]
        self.financial_sections = ["Balance_Sheet", "Income_Statement", "Cash_Flow"]

    # ----------------------------------------------------------------------
    def validate(self, **kwargs):
        data_dir = self._get_lake_path("raw")
        batch_files = sorted(
            f for f in os.listdir(data_dir)
            if f.startswith("batch_") and f.endswith(".jsonl")
        )

        if not batch_files:
            msg = f"âš ï¸ ê²€ì¦í•  ë°°ì¹˜ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {data_dir}"
            self.log.warning(msg)
            raise Exception(msg)

        results = []
        total_failed = 0
        total_passed = 0
        all_records = 0

        try:
            for batch_file in batch_files:
                batch_path = os.path.join(data_dir, batch_file)
                self.log.info(f"ğŸ” ë°°ì¹˜ ê²€ì¦ ì‹œì‘: {batch_file}")

                with open(batch_path, "r", encoding="utf-8") as f:
                    records = [json.loads(line) for line in f]

                batch_result = self._validate_records(records, batch_file)
                results.append(batch_result)
                all_records += batch_result["record_count"]

                if batch_result["status"] == "success":
                    total_passed += 1
                else:
                    total_failed += 1

                # ë°°ì¹˜ë³„ ìš”ì•½ ë¡œê·¸
                self.log.info(
                    f"ğŸ“Š {batch_file} ê²°ê³¼: {batch_result['status'].upper()} | "
                    f"ì´ {batch_result['record_count']}ê±´ | "
                    f"ì—ëŸ¬ {len(batch_result['errors'])} | ê²½ê³  {len(batch_result['warnings'])}"
                )
                for rr in batch_result["record_results"]:
                    self.log.info(
                        f"   - {rr['code']} â–¶ {rr['status'].upper()} "
                        f"({len(rr.get('errors', []))} errors, {len(rr.get('warnings', []))} warnings)"
                    )

                    # ê°œë³„ ê²½ê³  ìƒì„¸ ë¡œê·¸
                    for w in rr.get("warnings", []):
                        self.log.warning(f"      âš ï¸ {rr['code']} ê²½ê³  ì‚¬ìœ : {w}")

                    # ê°œë³„ ì˜¤ë¥˜ ìƒì„¸ ë¡œê·¸
                    for e in rr.get("errors", []):
                        self.log.error(f"      âŒ {rr['code']} ì˜¤ë¥˜ ì‚¬ìœ : {e}")

            final_status = "failed" if total_failed > 0 else "success"
            self.log.info(
                f"âœ… í€ë”ë©˜í„¸ ì „ì²´ ê²€ì¦ ì™„ë£Œ â€” ì´ {len(batch_files)}ê°œ ë°°ì¹˜, {all_records}ê±´ "
                f"(ì„±ê³µ {total_passed}, ì‹¤íŒ¨ {total_failed})"
            )

            summary_path = os.path.join(data_dir, "_validation_summary.json")
            with open(summary_path, "w", encoding="utf-8") as f:
                json.dump(
                    {
                        "timestamp": datetime.now().isoformat(),
                        "exchange_code": self.exchange_code,
                        "trd_dt": self.trd_dt,
                        "status": final_status,
                        "total_batches": len(batch_files),
                        "total_records": all_records,
                        "results": results,
                    },
                    f,
                    indent=2,
                    ensure_ascii=False,
                )
            self.log.info(f"ğŸ“‹ ê²€ì¦ ìš”ì•½ ì €ì¥: {summary_path}")

            if final_status == "failed":
                raise Exception(f"âŒ í€ë”ë©˜í„¸ ê²€ì¦ ì‹¤íŒ¨ ({total_failed}/{len(batch_files)}ê°œ ë°°ì¹˜)")

            return {"status": final_status, "batches": results}

        finally:
            deleted = 0
            for f in os.listdir(data_dir):
                if any(x in f for x in [".sample", ".parquet", "tmp_"]):
                    try:
                        os.remove(os.path.join(data_dir, f))
                        deleted += 1
                    except Exception:
                        pass
            if deleted:
                self.log.info(f"ğŸ§¹ ì„ì‹œíŒŒì¼ {deleted}ê°œ ì •ë¦¬ ì™„ë£Œ ({data_dir})")

    # ----------------------------------------------------------------------
    def _validate_records(self, records: list[dict], batch_name: str) -> dict:
        errors = []
        warnings = []
        record_results = []

        for rec in records:
            code = rec.get("General", {}).get("Code", "UNKNOWN")
            general = rec.get("General", {})
            sec_type = (general.get("Type") or "").lower()
            rec_errors, rec_warnings = [], []

            try:
                # âœ… ê³µí†µ General í•„ìˆ˜ í•„ë“œ
                for field in self.required_general_fields:
                    if not general.get(field):
                        rec_warnings.append(f"General.{field} ëˆ„ë½")

                if sec_type in ["etf"]:
                    # âœ… ETF ì „ìš© ê²€ì¦ ë¡œì§
                    etf_result = self._validate_etf_fields(rec)
                    rec_errors.extend(etf_result["errors"])
                    rec_warnings.extend(etf_result["warnings"])

                elif sec_type in ["common stock"]:
                    # âœ… ê¸°ì¡´ Common Stock ê²€ì¦ ë¡œì§
                    fin = rec.get("Financials", {})
                    if not fin:
                        rec_errors.append("Financials í•„ë“œ ì—†ìŒ")
                    else:
                        for section in self.financial_sections:
                            sec_data = fin.get(section, {})
                            if not sec_data:
                                rec_warnings.append(f"{section} ë°ì´í„° ì—†ìŒ")
                                continue
                            latest_period, latest_data = self._get_latest_period(sec_data)
                            if not latest_data:
                                rec_warnings.append(f"{section} ìµœì‹  ë°ì´í„° ì—†ìŒ")
                                continue
                            checks = self._check_financial_section(section, latest_data, code, latest_period)
                            rec_errors.extend(checks["errors"])
                            rec_warnings.extend(checks["warnings"])
                else:
                    rec_warnings.append(f"ì•Œ ìˆ˜ ì—†ëŠ” ì¢…ëª© íƒ€ì…: {sec_type}")

            except Exception as e:
                rec_errors.append(f"ë ˆì½”ë“œ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸: {str(e)}")

            record_results.append({
                "code": code,
                "type": sec_type,
                "status": "failed" if rec_errors else ("warning" if rec_warnings else "success"),
                "errors": rec_errors,
                "warnings": rec_warnings,
            })

            errors.extend([f"{code}: {msg}" for msg in rec_errors])
            warnings.extend([f"{code}: {msg}" for msg in rec_warnings])

        status = "failed" if errors else ("warning" if warnings else "success")
        return {
            "batch": batch_name,
            "status": status,
            "record_count": len(records),
            "errors": errors,
            "warnings": warnings,
            "record_results": record_results,
        }

    # ----------------------------------------------------------------------
    # âœ… ETF ì „ìš© ê²€ì¦ ë¡œì§ (Soda YAML ëŒ€ì‘)
    # ----------------------------------------------------------------------
    def _validate_etf_fields(self, rec: dict) -> dict:
        """
        Soda checks ëŒ€ì‘:
        - row_count > 0 â†’ ìë™ ì¶©ì¡±
        - duplicate_count(code) = 0 â†’ DAG ë ˆë²¨ì—ì„œ ê²€ì¦
        - missing_percent(field) < 5 â†’ í•´ë‹¹ í•„ë“œ ì¡´ì¬ ì—¬ë¶€ë§Œ í™•ì¸
        - avg(field) > 0 â†’ ìŒìˆ˜/0 ì—¬ë¶€ ê²€ì¦
        """
        errors = []
        warnings = []
        general = rec.get("General", {})
        code = general.get("Code", "UNKNOWN")
        data = rec.get("ETF_Data", {})

        assert data != {}, 'dataê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.'

        required_fields = [
            "TotalAssets",
            "Holdings_Count",
            "NetExpenseRatio",
            "Yield",
        ]

        for f in required_fields:
            val = data.get(f)
            if val is None:
                warnings.append(f"{f} ëˆ„ë½")
            else:
                try:
                    v = float(val)
                    if v < 0:
                        errors.append(f"{f} ìŒìˆ˜ê°’ ({v})")
                    elif f in ["TotalAssets", "Holdings_Count"] and v == 0:
                        errors.append(f"{f} 0ê°’ ({v})")
                except Exception:
                    errors.append(f"{f} ìˆ˜ì¹˜í˜• ë³€í™˜ ë¶ˆê°€ ({val})")

        return {"errors": errors, "warnings": warnings}

    # ----------------------------------------------------------------------
    def _get_latest_period(self, sec_data: dict):
        for key in ["yearly", "Yearly", "quarterly", "Quarterly"]:
            if key in sec_data and isinstance(sec_data[key], dict):
                values = sec_data[key]
                if values:
                    try:
                        latest_period = sorted(values.keys())[-1]
                        return latest_period, values[latest_period]
                    except Exception:
                        pass
        return None, None

    # ----------------------------------------------------------------------
    def _check_financial_section(self, section: str, data: dict, code: str, period: str) -> dict:
        errors, warnings = [], []

        def invalid_num(val):
            try:
                v = float(val)
                return pd.isna(v) or v == 0
            except Exception:
                return True

        if section == "Balance_Sheet":
            keys = ["totalAssets", "totalLiab"]
        elif section == "Income_Statement":
            keys = ["netIncome", "totalRevenue"]
        # elif section == "Cash_Flow":
        #     keys = ["OperatingCashFlow", "FreeCashFlow"]
        else:
            keys = []

        for k in keys:
            v = data.get(k)
            if v is None:
                warnings.append(f"{section}.{period}.{k} ëˆ„ë½")
            elif invalid_num(v):
                errors.append(f"{section}.{period}.{k} ë¹„ì •ìƒê°’ ({v})")

        return {"errors": errors, "warnings": warnings}
