# plugins/validators/split_validator.py
import os
import json
import tempfile
import pandas as pd
import pandera.pandas as pa
from pandera import Column, Check
from plugins.validators.base_validator import BaseDataValidator
from soda.scan import Scan
import yaml

class EquitySplitValidator(BaseDataValidator):
    """ê±°ë˜ì†Œë³„ ì•¡ë©´ë¶„í• (Splits) ë°ì´í„° ê²€ì¦ Validator"""

    def __init__(self, exchange_code: str, trd_dt: str, data_domain: str = "splits"):
        super().__init__(exchange_code, trd_dt, data_domain)
        self.schema = self._get_schema()

    # ============================================================
    # 1ï¸âƒ£ Pandera ìŠ¤í‚¤ë§ˆ ì •ì˜
    # ============================================================
    def _get_schema(self):
        # eod-bulk-last-day ?type=splits ê²°ê³¼: code, exchange, date, split
        return pa.DataFrameSchema(
            columns={
                "code": Column(str, nullable=False, coerce=True),
                "exchange": Column(str, nullable=False, coerce=True),
                "date": Column(str, nullable=False, coerce=True, checks=[
                    # YYYY-MM-DD í¬ë§· ê²€ì¦
                    Check(lambda s: pd.to_datetime(s, format="%Y-%m-%d", errors="coerce").notna(),
                          error="âŒ 'date' must be YYYY-MM-DD"),
                ]),
                "split": Column(str, nullable=False, coerce=True, checks=[
                    # "A/B" í˜•íƒœ(ì†Œìˆ˜ í—ˆìš©) ê²€ì¦
                    Check.str_matches(r"^\d+(\.\d+)?/\d+(\.\d+)?$",
                                      error="âŒ 'split' must look like '1/10' or '1.000000/10.000000'")
                ]),
            },
            strict=False,
        )

    # ============================================================
    # 2ï¸âƒ£ ì „ì²´ ê²€ì¦ ì‹¤í–‰
    # ============================================================
    def validate(self, **kwargs):
        raw_dir = self._get_lake_path("raw")
        files = [f for f in os.listdir(raw_dir) if f.endswith(".json") or f.endswith(".jsonl")]
        if not files:
            print(f"âš ï¸ ê²€ì¦ ëŒ€ìƒ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {raw_dir}")
            return

        all_records = []
        for file in files:
            path = os.path.join(raw_dir, file)
            with open(path, "r", encoding="utf-8") as f:
                try:
                    if file.endswith(".jsonl"):
                        all_records.extend([json.loads(line) for line in f if line.strip()])
                    else:
                        all_records.extend(json.load(f))
                except Exception as e:
                    print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {file} | {e}")

        df = pd.DataFrame(all_records)
        if df.empty:
            raise AssertionError("âŒ ê²€ì¦í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # âœ… Pandera ìŠ¤í‚¤ë§ˆ ê²€ì¦
        try:
            self.schema.validate(df)
            print(f"âœ… Pandera ê²€ì¦ í†µê³¼ ({len(df)} records)")
        except Exception as e:
            raise AssertionError(f"âŒ Pandera ê²€ì¦ ì‹¤íŒ¨: {e}")

        # âœ… Soda Core ê²€ì¦ ì‹¤í–‰
        temp_path = os.path.join(raw_dir, "_splits_temp.parquet")

        df.to_parquet(temp_path, index=False)
        self._run_soda_on_parquet(temp_path, mode="splits")

    # ============================================================
    # 3ï¸âƒ£ Soda ì‹¤í–‰ ë¡œì§
    # ============================================================
    def _run_soda_on_parquet(self, parquet_path: str, mode: str = "splits"):
        base_dir = "/opt/airflow/plugins/soda/checks"
        soda_check_file = os.path.join(base_dir, f"splits_checks.yml")

        if not os.path.exists(soda_check_file):
            print(f"âš ï¸ {soda_check_file} ì—†ìŒ â€” ê±´ë„ˆëœ€.")
            return

        tmp_config = {"data_source my_duckdb": {"type": "duckdb", "path": ":memory:"}}
        with tempfile.NamedTemporaryFile(mode="w", suffix=".yml", delete=False) as tmp_file:
            yaml.dump(tmp_config, tmp_file)
            tmp_config_path = tmp_file.name

        scan = Scan()
        scan.set_data_source_name("my_duckdb")
        scan.add_configuration_yaml_file(tmp_config_path)
        scan.add_sodacl_yaml_files(soda_check_file)
        scan._data_source_manager.get_data_source("my_duckdb").connection.execute(
            f"CREATE TABLE splits AS SELECT * FROM read_parquet('{parquet_path}')"
        )

        exit_code = scan.execute()
        print(f"ğŸ§ª Soda Scan ì™„ë£Œ (exit_code={exit_code}, mode={mode})")
        if exit_code != 0:
            raise AssertionError(f"âŒ Soda ê²€ì¦ ì‹¤íŒ¨: exit_code={exit_code}, mode={mode}")

        os.unlink(tmp_config_path)
