"""
plugins/pipelines/warehouse/fundamentals_ticker_split_pipeline.py

üíæ ÌéÄÎçîÎ©òÌÑ∏ Ìã∞Ïª§Î≥Ñ Key-Split ÌååÏù¥ÌîÑÎùºÏù∏
- Data Lake(validated) ‚Üí Data Warehouse(snapshot)
- ticker Îã®ÏúÑ JSONÏùÑ keyÎ≥Ñ ParquetÏúºÎ°ú Î∂ÑÎ¶¨ Ï†ÄÏû•
- OOM Î∞©ÏßÄÎ•º ÏúÑÌï¥ ÌååÏùº Îã®ÏúÑ ÏàúÏ∞® Î≥ÄÌôò ÏàòÌñâ
"""

import json
import pandas as pd
from datetime import datetime, timezone
from typing import Dict, Any, Optional
from pathlib import Path

from plugins.pipelines.warehouse.base_warehouse_pipeline import BaseWarehousePipeline
from plugins.config.constants import DATA_LAKE_ROOT, DATA_WAREHOUSE_ROOT, WAREHOUSE_DOMAINS, DOMAIN_GROUPS


class FundamentalsTickerSplitPipeline(BaseWarehousePipeline):
    """
    ‚úÖ Fundamentals Ticker-Split Warehouse Pipeline
    ----------------------------------------------------------------------
    [ÌååÏù¥ÌîÑÎùºÏù∏ Íµ¨Ï°∞]
    1Ô∏è‚É£ Data Lake validated fundamentals JSON ÌååÏùº Î°úÎìú
    2Ô∏è‚É£ Í∞Å Ìã∞Ïª§Î≥Ñ Ìè¥Îçî(ticker=XXXX) ÏÉùÏÑ±
    3Ô∏è‚É£ JSON ÏµúÏÉÅÏúÑ Key(General, Highlights, Financials Îì±)Î•º Í∞ÅÍ∞Å ParquetÏúºÎ°ú Ï†ÄÏû•
    4Ô∏è‚É£ Î©îÌÉÄÏ†ïÎ≥¥(_build_meta.json) Í∏∞Î°ù
    """

    def __init__(
        self,
        trd_dt: str,
        exchange_code: str,
        vendor: Optional[str] = "eodhd",
        domain_group: Optional[str] = DOMAIN_GROUPS["equity"],
        **kwargs
    ):
        super().__init__(
            domain=WAREHOUSE_DOMAINS["fundamentals"],
            domain_group=domain_group,
            trd_dt=trd_dt,
            vendor_priority=[vendor],
        )
        self.exchange_code = exchange_code
        self.vendor = vendor
        self.trigger_source = kwargs.get("trigger_source", None)

    # ============================================================
    # üìò 1Ô∏è‚É£ Ìã∞Ïª§ Îã®ÏúÑ Fundamentals ‚Üí Warehouse Î≥ÄÌôò Î°úÏßÅ
    # ============================================================
    def _transform_business_logic(self, **kwargs) -> pd.DataFrame:
        """
        fundamentals JSONÏùÑ tickerÎ≥Ñ key-split ParquetÏúºÎ°ú Î≥ÄÌôò
        """
        vendor = self.vendor
        exchange_code = self.exchange_code
        domain_group = self.domain_group
        trd_dt = self.trd_dt

        self.log.info(
            f"üèóÔ∏è Building FundamentalsTickerSplitPipeline | "
            f"exchange_code={exchange_code}, trd_dt={trd_dt}"
        )

        # ‚úÖ ÏûÖÎ†• / Ï∂úÎ†• Í≤ΩÎ°ú
        lake_dir = (
            Path(DATA_LAKE_ROOT)
            / "validated"
            / domain_group
            / "fundamentals"
            / f"vendor={vendor}"
            / f"exchange_code={exchange_code}"
            / f"trd_dt={trd_dt}"
        )

        warehouse_dir = (
            Path(DATA_WAREHOUSE_ROOT)
            / "snapshot"
            / domain_group
            / "fundamentals"
            / f"trd_dt={trd_dt}"
            / f"exchange_code={exchange_code}"
        )
        warehouse_dir.mkdir(parents=True, exist_ok=True)

        if not lake_dir.exists():
            raise FileNotFoundError(f"‚ùå Source directory not found: {lake_dir}")

        json_files = list(lake_dir.glob("*.json"))
        if not json_files:
            raise FileNotFoundError(f"‚ùå No fundamentals JSON files found in {lake_dir}")

        total_tickers = 0
        total_keys = set()

        # =======================================================
        # üîÅ ÌååÏùº Îã®ÏúÑ Î≥ÄÌôò (OOM Î∞©ÏßÄ)
        # =======================================================
        for f in json_files:
            ticker = f.stem
            try:
                data = json.load(open(f, "r", encoding="utf-8"))
                if not isinstance(data, dict):
                    self.log.warning(f"‚ö†Ô∏è Invalid format for {f.name} (skip)")
                    continue

                ticker_dir = warehouse_dir / f"ticker={ticker}"
                ticker_dir.mkdir(parents=True, exist_ok=True)

                # Í∞Å keyÎ≥ÑÎ°ú parquet Ï†ÄÏû•
                for key, value in data.items():
                    if not isinstance(value, (dict, list)):
                        continue

                    key_lower = key.lower()
                    total_keys.add(key_lower)
                    out_path = ticker_dir / f"{key_lower}.parquet"

                    df = pd.DataFrame([value]) if isinstance(value, dict) else pd.DataFrame(value)
                    if df.empty:
                        continue

                    df["ticker"] = ticker
                    df["exchange_code"] = exchange_code
                    df["trd_dt"] = trd_dt

                    # Í∞ùÏ≤¥Ìòï Ïª¨ÎüºÏùÄ Î¨∏ÏûêÏó¥Î°ú Î≥ÄÌôò
                    for col in df.select_dtypes(include=["object"]).columns:
                        df[col] = df[col].astype(str)

                    df.to_parquet(out_path, index=False)
                total_tickers += 1

                if total_tickers % 100 == 0:
                    self.log.info(f"üì¶ Processed {total_tickers:,} tickers so far...")

            except Exception as e:
                self.log.warning(f"‚ö†Ô∏è Failed to process {f.name}: {e}")

        # =======================================================
        # üßæ Î©îÌÉÄÌååÏùº Í∏∞Î°ù
        # =======================================================
        meta_info = {
            "snapshot_dt": trd_dt,
            "exchange_code": exchange_code,
            "total_tickers": total_tickers,
            "keys_generated": sorted(list(total_keys)),
            "build_time": datetime.now(timezone.utc).isoformat(),
            "source_path": str(lake_dir),
            "output_path": str(warehouse_dir),
        }

        meta_path = warehouse_dir / "_build_meta.json"
        with open(meta_path, "w", encoding="utf-8") as mf:
            json.dump(meta_info, mf, indent=2, ensure_ascii=False)

        self.log.info(
            f"‚úÖ Fundamentals ticker-split build complete "
            f"| {total_tickers:,} tickers | {len(total_keys)} key types | path={warehouse_dir}"
        )
        return pd.DataFrame([meta_info])

    # ============================================================
    # üìò 2Ô∏è‚É£ Ï†ÑÏ≤¥ ÎπåÎìú Ïã§Ìñâ (Entry Point)
    # ============================================================
    def build(self, **kwargs) -> Dict[str, Any]:
        self.log.info("üöÄ [START] FundamentalsTickerSplitPipeline")
        try:
            result_df = self._transform_business_logic(**kwargs)
            meta = self.save_metadata(
                row_count=len(result_df),
                exchange_code=self.exchange_code,
                vendor=self.vendor,
                context=kwargs.get("context"),
            )

            self.log.info(
                f"‚úÖ [BUILD COMPLETE] fundamentals_ticker_split | "
                f"{self.exchange_code} | trd_dt={self.trd_dt}"
            )
            return meta
        except Exception as e:
            self.log.error(f"‚ùå Build failed: {e}")
            raise
        finally:
            self.cleanup()
