"""
plugins/pipelines/warehouse/exchange_master_pipeline.py

ğŸ’¾ ê±°ë˜ì†Œ ë§ˆìŠ¤í„° íŒŒì´í”„ë¼ì¸
- Data Lake(validated) â†’ Data Warehouse(exchange)
- BaseWarehousePipeline + transform_utils ê¸°ë°˜ í‘œì¤€í˜•
"""

import pandas as pd
from typing import Dict, Any, Optional, List

from plugins.pipelines.warehouse.base_warehouse_pipeline import BaseWarehousePipeline
from plugins.config.constants import WAREHOUSE_DOMAINS, DOMAIN_GROUPS
from plugins.utils.transform_utils import normalize_columns, safe_merge

from plugins.utils.loaders.lake.exchange_loader import load_exchange_list
from plugins.utils.loaders.lake.exchange_holiday_loader import load_exchange_holiday_list


class ExchangeMasterPipeline(BaseWarehousePipeline):
    """
    âœ… ê±°ë˜ì†Œ ë§ˆìŠ¤í„° íŒŒì´í”„ë¼ì¸ (Warehouse Domain: exchange)

    [íŒŒì´í”„ë¼ì¸ êµ¬ì¡°]
    1ï¸âƒ£ Data Lake validated ë°ì´í„° ë¡œë“œ
    2ï¸âƒ£ ê±°ë˜ì†Œ ë°ì´í„° ì •ê·œí™”
    3ï¸âƒ£ íœ´ì¥ì¼ ë°ì´í„° ë³‘í•©
    4ï¸âƒ£ Pandera ìŠ¤í‚¤ë§ˆ ê¸°ì¤€ ì»¬ëŸ¼ ì •ë ¬ ë° ì €ì¥
    """

    def __init__(self, trd_dt: str, vendor: str = None, **kwargs):
        super().__init__(
            domain=WAREHOUSE_DOMAINS["exchange"],
            domain_group=DOMAIN_GROUPS["equity"],
            trd_dt=trd_dt,
            vendor=vendor,
        )
        self.trigger_source = kwargs.get("trigger_source", None)  # âœ… ë¡œê·¸ìš©ìœ¼ë¡œ ì €ì¥

    # ============================================================
    # ğŸ“˜ 1ï¸âƒ£ ê±°ë˜ì†Œ ë¦¬ìŠ¤íŠ¸ ì •ê·œí™”
    # ============================================================
    def _normalize_exchange_list(self, df: pd.DataFrame) -> pd.DataFrame:
        df = normalize_columns(df)

        code_col = next(
            (c for c in ("code", "exchange_code", "mic", "operatingmic") if c in df.columns),
            None
        )
        if not code_col:
            raise ValueError("âŒ ê±°ë˜ì†Œ ë°ì´í„°ì— code/exchange_code ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

        normalized = pd.DataFrame({
            "country_code": df.get("countryiso3", df.get("country_code", "")),
            "country_name": df.get("country", df.get("country_name", "")),
            "exchange_code": df[code_col],
            "exchange_name": df.get("name", df.get("exchange_name", "")),
            "currency": df.get("currency", ""),
            "country_iso2": df.get("countryiso2", ""),
            "timezone": df.get("timezone", ""),
            "operating_mic": df.get("operatingmic", df.get(code_col, "")),
            "active_tickers": df.get("activetickers", df.get("active_tickers", None)),
            "previous_day_updated_tickers": df.get(
                "previous_day_updated_tickers", df.get("previousdayupdatedtickers", None)
            ),
            "updated_tickers": df.get("updated_tickers", df.get("updatedtickers", None)),
        })

        for col in ["country_code", "exchange_code", "exchange_name"]:
            normalized[col] = normalized[col].astype(str).str.strip().str.upper()

        return normalized[
            (normalized["country_code"] != "") &
            (normalized["exchange_code"] != "")
        ]

    # ============================================================
    # ğŸ“˜ 2ï¸âƒ£ íœ´ì¥ì¼ ì •ê·œí™”
    # ============================================================
    def _normalize_exchange_holiday(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        íœ´ì¥ì¼ ë°ì´í„° í‘œì¤€í™” + ì»¬ëŸ¼ ìŠ¬ë¦¼í™”
        - exchange_code, holiday_name, holiday_date 3ê°œë§Œ ë‚¨ê¹€
        """
        df = normalize_columns(df)

        # 1) ê±°ë˜ì†Œ ì‹ë³„ ì»¬ëŸ¼ ì •ê·œí™”
        exch_col = next(
            (c for c in ("exchange", "exchange_code", "code", "mic", "operatingmic") if c in df.columns),
            None
        )
        if exch_col is None:
            self.log.warning("âš ï¸ holiday_dfì— ê±°ë˜ì†Œ ì‹ë³„ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (ë³‘í•© ìƒëµ)")
            df["exchange_code"] = None
        else:
            df = df.rename(columns={exch_col: "exchange_code"})

        # 2) í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë‚¨ê¹€
        #   - ì›ë³¸ì— ë”°ë¼ holiday_dateê°€ date/Datetime/string í˜¼ì¬ ê°€ëŠ¥ â†’ pandas datetime ìºìŠ¤íŒ…
        keep_cols = []
        if "holiday_name" in df.columns:
            keep_cols.append("holiday_name")
        if "holiday_date" in df.columns:
            keep_cols.append("holiday_date")

        # ì—†ìœ¼ë©´ ìƒì„±(ë„)
        if "holiday_name" not in df.columns:
            df["holiday_name"] = None
        if "holiday_date" not in df.columns:
            df["holiday_date"] = None

        df = df[["exchange_code", "holiday_name", "holiday_date"]]

        # 3) íƒ€ì… ë³´ì •
        try:
            df["holiday_date"] = pd.to_datetime(df["holiday_date"], errors="coerce", utc=False)
        except Exception:
            pass

        # exchange_code ëŒ€ë¬¸ì/íŠ¸ë¦¼
        df["exchange_code"] = df["exchange_code"].astype(str).str.strip().str.upper()


        return df

    # ============================================================
    # ğŸ“˜ 3ï¸âƒ£ ë„ë©”ì¸ ë³€í™˜ ë¡œì§ (Pandera ìŠ¤í‚¤ë§ˆ ì •í•©ì„± ë°˜ì˜)
    # ============================================================
    def _transform_business_logic(
            self,
            exchange_list: pd.DataFrame,
            exchange_holiday: Optional[pd.DataFrame] = None,
            **kwargs
    ) -> pd.DataFrame:
        """
        ê±°ë˜ì†Œ + (ì¶•ì•½ëœ) íœ´ì¥ì¼ í†µí•© ë³€í™˜
        - íœ´ì¥ì¼ì€ ê¸°ì¤€ì¼(self.trd_dt) ì´í›„ 'ê°€ì¥ ê°€ê¹Œìš´ íœ´ì¥ì¼' 1ê±´ë§Œ ë‚¨ê²¨ì„œ join
        """
        # 1) ê±°ë˜ì†Œ ì •ê·œí™” & ì¤‘ë³µ ì œê±°
        normalized = self._normalize_exchange_list(exchange_list)
        deduped = normalized.drop_duplicates(subset=["exchange_code"], keep="first")

        # 2) íœ´ì¥ì¼ ì¶•ì•½: ê¸°ì¤€ì¼ ì´í›„ ì²« íœ´ì¥ì¼ë§Œ ë‚¨ê¹€
        if exchange_holiday is not None and not exchange_holiday.empty:
            holiday_df = self._normalize_exchange_holiday(exchange_holiday)

            # ê¸°ì¤€ì¼ íŒŒì‹±
            ref_dt = pd.to_datetime(self.trd_dt)

            # ê¸°ì¤€ì¼ ì´í›„(>=)ë§Œ í•„í„°
            future_holidays = holiday_df.loc[
                (holiday_df["holiday_date"].notna()) & (holiday_df["holiday_date"] >= ref_dt)
                ].copy()

            # ê°€ì¥ ê°€ê¹Œìš´ íœ´ì¥ì¼ 1ê±´/ê±°ë˜ì†Œ
            #   sort asc â†’ groupby().head(1) or idxmin
            future_holidays = future_holidays.sort_values(["exchange_code", "holiday_date"], ascending=[True, True])
            next_holiday = future_holidays.groupby("exchange_code", as_index=False).first()
            # í•„ìš” ì»¬ëŸ¼ë§Œ ë³´ì¥
            next_holiday = next_holiday[["exchange_code", "holiday_name", "holiday_date"]]

            # 3) ë³‘í•© (ìŠ¬ë¦¼í•´ì§„ dfë§Œ JOIN)
            merged = safe_merge(
                left=deduped,
                right=next_holiday,
                left_on="exchange_code",
                right_on="exchange_code",
                how="left",
                suffixes=("", "_holiday"),
            )
        else:
            merged = deduped

        # 4) Pandera ìŠ¤í‚¤ë§ˆ ëˆ„ë½ ì»¬ëŸ¼ ë³´ì •
        for col in ["open_time", "close_time", "working_days"]:
            if col not in merged.columns:
                merged[col] = None

        # 5) ì»¬ëŸ¼ëª… í‘œì¤€í™” (ì›ë³¸ api í‘œê¸° â†’ í‘œì¤€ ìŠ¤í‚¤ë§ˆ í‘œê¸°)
        rename_map = {
            "activetickers": "active_tickers",
            "previousdayupdatedtickers": "previous_day_updated_tickers",
            "updatedtickers": "updated_tickers",
        }
        merged = merged.rename(columns=rename_map)

        # âœ… ìˆ˜ì¹˜ ì»¬ëŸ¼ í˜• ë³€í™˜
        for col in ["active_tickers", "previous_day_updated_tickers", "updated_tickers"]:
            if col in merged.columns:
                merged[col] = pd.to_numeric(merged[col], errors="coerce")

        # 6) ì™„ì „ ë°©ì–´: ì»¬ëŸ¼ ì¤‘ë³µ ì œê±° + ì—¬ë¶„ ì»¬ëŸ¼ ë“œë(holiday_* ì ‘ë¯¸ì‚¬ ë“±)
        merged = merged.loc[:, ~merged.columns.duplicated(keep="first")]
        drop_extras = [c for c in merged.columns if c.endswith("_holiday")]
        if drop_extras:
            merged = merged.drop(columns=drop_extras, errors="ignore")

        # 7) ì»¬ëŸ¼ ìˆœì„œ í‘œì¤€í™” (Pandera ìŠ¤í‚¤ë§ˆ ê¸°ì¤€)
        final_df = self._reorder_columns(merged)
        return final_df


    def _load_source_datasets(self) -> dict[str, pd.DataFrame]:
        """âœ… Domainë³„ Loaderë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ëª…ì‹œì  ë²„ì „"""


        exchange_df = load_exchange_list(
            domain_group=self.domain_group,
            vendor=self.vendor,
            trd_dt=self.trd_dt
        )

        exchanges = exchange_df[exchange_df['CountryISO3'] == self.country_code]['Code'].tolist()

        for exchange_code in exchanges:
            exchange_holiday_df = load_exchange_holiday_list(
                domain_group=self.domain_group,
                vendor=self.vendor,
                trd_dt=self.trd_dt,
                exchange_code=exchange_code
            )


        return {
            "exchange_holiday": exchange_holiday_df,
            "exchange_list": exchange_df
        }


    # ============================================================
    # ğŸ“˜ 5ï¸âƒ£ ì „ì²´ ë¹Œë“œ ì‹¤í–‰
    # ============================================================
    def build(self, **kwargs) -> Dict[str, Any]:
        self.log.info(f"ğŸ—ï¸ Building ExchangeMasterPipeline | snapshot_dt={self.trd_dt}")

        sources = self._load_source_datasets()
        exchange_df = sources.get("exchange_list")
        holiday_df = sources.get("exchange_holiday")

        if exchange_df is None or exchange_df.empty:
            raise FileNotFoundError("âŒ exchange_list ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        final_df = self._transform_business_logic(
            exchange_list=exchange_df,
            exchange_holiday=holiday_df,
        )

        # âœ… ì €ì¥ + ë©”íƒ€ ê¸°ë¡
        self.save_parquet(final_df)
        meta = self.save_metadata(
            row_count=len(final_df),
            source_datasets=list(sources.keys()),
            metrics={"vendor": self.vendor},
            context=kwargs.get("context"),
        )

        self.log.info(f"âœ… [BUILD COMPLETE] exchange_master | {len(final_df):,} rows")
        return meta
