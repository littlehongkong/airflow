# plugins/pipelines/fundamental_pipeline.py

from typing import Dict, List
import json
from pathlib import Path
from plugins.hooks.eodhd_hook import EODHDHook
from plugins.pipelines.base_equity_pipeline import BaseEquityPipeline
from plugins.config.constants import DOMAIN_GROUPS


class FundamentalPipeline(BaseEquityPipeline):
    """
    í€ë”ë©˜í„¸(Fundamentals) ë°ì´í„° ìˆ˜ì§‘ ë° ì ì¬ íŒŒì´í”„ë¼ì¸
    --------------------------------------------------------
    âœ… DAGì—ì„œ ì „ë‹¬ë°›ì€ ì¢…ëª©(batch_symbols)ë§Œ ìˆ˜ì§‘
    âœ… êµ¬ì¡°: /exchange_code=KR/snapshot_dt=YYYY-MM-DD/{symbol}.json
    """

    def __init__(self, domain: str, exchange_code: str, trd_dt: str, domain_group: str = None):
        super().__init__(domain, exchange_code, trd_dt, domain_group=domain_group or DOMAIN_GROUPS.get(domain, "equity"))
        self.hook = EODHDHook()


    def fetch(self, **kwargs):
        symbol = kwargs.get('symbol')
        data = self.hook.get_fundamentals(symbol=symbol)
        return data


    # ------------------------------------------------------------------
    # âœ… Fetch + Load í†µí•© ì‹¤í–‰ (DAGì—ì„œ ì¢…ëª© ì „ë‹¬)
    # ------------------------------------------------------------------
    def fetch_and_load(self, **kwargs):
        """
        Fundamentals ìˆ˜ì§‘ ë° ì €ì¥
        - DAGì—ì„œ batch_symbolsê°€ ì „ë‹¬ë˜ë©´ í•´ë‹¹ ì¢…ëª©ë§Œ ìˆ˜ì§‘
        - ì „ë‹¬ë˜ì§€ ì•Šìœ¼ë©´ symbol_list.parquetì„ ìë™ ë¡œë“œí•˜ì—¬ ìˆ˜ì§‘
        """
        import pandas as pd
        from plugins.utils.symbol_loader import load_symbols_from_datalake_pd
        from plugins.config import constants as C

        self.log.info(f"ğŸš€ Fundamentals íŒŒì´í”„ë¼ì¸ ì‹œì‘ ({self.exchange_code}, {self.trd_dt})")

        exchange_code = kwargs.get("exchange_code", self.exchange_code)
        self.exchange_code = exchange_code
        trd_dt = kwargs.get("trd_dt", self.trd_dt)

        # ----------------------------------------------------------------------
        # âœ… 1ï¸âƒ£ ìˆ˜ì§‘ ëŒ€ìƒ ì‹¬ë³¼ ê²°ì •
        # ----------------------------------------------------------------------
        batch_symbols = kwargs.get("batch_symbols")

        if batch_symbols:
            self.log.info(f"ğŸ“¦ DAGì—ì„œ ì „ë‹¬ëœ batch_symbols: {len(batch_symbols)}ê°œ")
            symbols_to_process = [s.strip().upper() for s in batch_symbols if s]
        else:
            self.log.info(f"ğŸ“¦ batch_symbols ë¯¸ì „ë‹¬ â†’ symbol_list.parquet ìë™ ë¡œë“œ")
            try:
                df = load_symbols_from_datalake_pd(
                    exchange_code=exchange_code,
                    trd_dt=trd_dt,
                    vendor=C.VENDORS["eodhd"],
                    domain_group=C.DOMAIN_GROUPS["equity"],
                )
                symbols_to_process = df["Code"].dropna().astype(str).str.upper().unique().tolist()
                self.log.info(f"ğŸ“Š {exchange_code} ê±°ë˜ì†Œì—ì„œ {len(symbols_to_process):,}ê°œ ì¢…ëª© ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                raise FileNotFoundError(f"âŒ symbol_list parquet ë¡œë“œ ì‹¤íŒ¨: {e}")

        # ----------------------------------------------------------------------
        # âœ… 2ï¸âƒ£ ì €ì¥ ê²½ë¡œ ë° ê¸°ì¡´ ìˆ˜ì§‘ ì¢…ëª© í™•ì¸
        # ----------------------------------------------------------------------
        kwargs["partition_key_name"] = kwargs.get("partition_key_name", "trd_dt")
        kwargs["geo_key_name"] = kwargs.get("geo_key_name", "exchange_code")
        target_dir, base_metadata = self._get_lake_path_and_metadata(**kwargs)

        existing_symbols = self._get_existing_symbols(target_dir)
        symbols_to_fetch = [s for s in symbols_to_process if s not in existing_symbols]

        if not symbols_to_fetch:
            self.log.info("âœ… ëª¨ë“  ì¢…ëª©ì´ ì´ë¯¸ ìˆ˜ì§‘ë˜ì–´ ìˆìŠµë‹ˆë‹¤ â€” ìŠ¤í‚µ")
            return {"status": "skipped", "records": 0}

        # ----------------------------------------------------------------------
        # âœ… 3ï¸âƒ£ ì¢…ëª©ë³„ ìˆ˜ì§‘ ë° ì €ì¥
        # ----------------------------------------------------------------------
        total_saved = 0
        for sym in symbols_to_fetch:
            try:
                data = self.fetch(symbol=f"{sym}.{exchange_code}")
                if not data:
                    self.log.warning(f"âš ï¸ {sym} ë°ì´í„° ì—†ìŒ â€” ê±´ë„ˆëœ€")
                    continue

                records, meta = self._standardize_fetch_output(data)
                if not records:
                    continue

                file_path = target_dir / f"{sym}.json"
                with open(file_path, "w", encoding="utf-8") as f:
                    json.dump(records[0], f, ensure_ascii=False)

                total_saved += 1
            except Exception as e:
                self.log.error(f"âŒ {sym} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue

        # ----------------------------------------------------------------------
        # âœ… 4ï¸âƒ£ ë©”íƒ€ ì €ì¥
        # ----------------------------------------------------------------------
        self._save_source_meta(
            target_dir=target_dir,
            record_count=total_saved,
            source_meta={
                "vendor": "EODHD",
                "endpoint": "api/fundamentals",
                "exchange_code": exchange_code,
                "symbols_collected": total_saved,
                "symbols_total": len(symbols_to_process),
                "existing_symbols": len(existing_symbols),
            },
        )

        self.log.info(
            f"ğŸ¯ Fundamentals ì™„ë£Œ ({exchange_code}, {self.trd_dt}) - {total_saved:,}/{len(symbols_to_process):,} symbols"
        )
        return {"status": "success", "records": total_saved}

    # ------------------------------------------------------------------
    # âœ… ê¸°ì¡´ ì‹¬ë³¼ í™•ì¸ (ì´ë¯¸ ì €ì¥ëœ íŒŒì¼ íƒìƒ‰)
    # ------------------------------------------------------------------
    def _get_existing_symbols(self, target_dir: Path) -> set[str]:
        symbols = set()
        if not target_dir.exists():
            return symbols

        for f in target_dir.glob("*.json"):
            symbols.add(f.stem.upper())

        self.log.info(f"ğŸ§­ ê¸°ì¡´ ìˆ˜ì§‘ ì¢…ëª© {len(symbols):,}ê±´ í™•ì¸ë¨")
        return symbols
