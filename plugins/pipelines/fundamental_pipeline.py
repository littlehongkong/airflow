# plugins/pipelines/fundamental_pipeline.py
from typing import Any, Dict, List
import math
from plugins.hooks.eodhd_hook import EODHDHook
from plugins.pipelines.base_equity_pipeline import BaseEquityPipeline


class FundamentalPipeline(BaseEquityPipeline):
    """
    í€ë”ë©˜í„¸(Fundamentals) ë°ì´í„° ìˆ˜ì§‘ ë° ì ì¬ íŒŒì´í”„ë¼ì¸
    --------------------------------------------------------
    âœ… ë‹¤ë¥¸ íŒŒì´í”„ë¼ì¸(ExchangeInfoPipeline ë“±)ê³¼ ë™ì¼í•œ êµ¬ì¡° ìœ ì§€
    âœ… ë‹¨, ì¢…ëª©ë³„ í˜¸ì¶œ ë° ë°°ì¹˜ ë‹¨ìœ„ ì €ì¥(batch_0001.jsonl ë“±)ë§Œ ì°¨ë³„í™”
    """

    def __init__(self, data_domain: str, exchange_code: str, trd_dt: str):
        super().__init__(data_domain, exchange_code, trd_dt)
        self.hook = EODHDHook()
        self.batch_size = 40  # âœ… ë°°ì¹˜ ë‹¨ìœ„ ì €ì¥ (40ì¢…ëª©ì”©)

    # ------------------------------------------------------------------
    # âœ… 1ï¸âƒ£ Fetch
    # ------------------------------------------------------------------
    def fetch(self, **kwargs):
        tickers = kwargs.get("tickers", ['TSLA.US', 'AAPL.US', 'TMF.US', 'LABU.US'])
        all_records = []
        source_meta = None

        for ticker in tickers:
            try:
                data = self.hook.get_fundamentals(
                    symbol=ticker
                )
                records, meta = self._standardize_fetch_output(data)  # âœ… ì–¸íŒ¨í‚¹
                all_records.extend(records)  # âœ… flatten list[dict]
                source_meta = meta  # ë§ˆì§€ë§‰ ë©”íƒ€ë§Œ ê¸°ë¡ (í˜¹ì€ ë³‘í•© ê°€ëŠ¥)

            except Exception as e:
                self.log.error(f"âŒ {ticker} í€ë”ë©˜í„¸ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue

        self.log.info(f"âœ… í€ë”ë©˜í„¸ ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(all_records)}ê±´")
        return all_records, source_meta

    # ------------------------------------------------------------------
    # âœ… 2ï¸âƒ£ Load
    # ------------------------------------------------------------------
    def load(self, records: List[Dict], **kwargs):
        """
        ìˆ˜ì§‘ëœ í€ë”ë©˜í„¸ ë°ì´í„°ë¥¼ ë°°ì¹˜ ë‹¨ìœ„ë¡œ JSON Linesë¡œ ì ì¬í•©ë‹ˆë‹¤.
        ë‹¤ë¥¸ íŒŒì´í”„ë¼ì¸ê³¼ ë™ì¼í•œ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©°, íŒŒì¼ëª…ë§Œ batch_*.jsonlë¡œ êµ¬ë¶„í•©ë‹ˆë‹¤.
        """

        if not records:
            self.log.warning("âš ï¸ ì ì¬í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ğŸ”¹ ê³µí†µ ë©”íƒ€ë°ì´í„° ë° ì €ì¥ ê²½ë¡œ í™•ë³´
        kwargs["partition_key_name"] = kwargs.get("partition_key_name", "trd_dt")
        kwargs["geo_key_name"] = kwargs.get("geo_key_name", "exchange_code")

        target_dir, base_metadata = self._get_lake_path_and_metadata(**kwargs)

        total_records = len(records)
        total_batches = math.ceil(total_records / self.batch_size)

        for i in range(total_batches):
            batch_records = records[i * self.batch_size : (i + 1) * self.batch_size]
            file_name = f"batch_{i + 1:04d}.jsonl"

            self.log.info(f"{file_name} >> {batch_records}")

            self._write_records_to_lake(
                records=batch_records,
                target_dir=target_dir,
                base_metadata=base_metadata,
                file_name=file_name,
            )

        meta = kwargs.get("meta", {}) or {}

        # ğŸ”¹ _source_meta.json ì €ì¥
        self._save_source_meta(
            target_dir=target_dir,
            record_count=total_records,
            source_meta={**meta, "batches": total_batches}
        )

        self.log.info(f"âœ… í€ë”ë©˜í„¸ ë°ì´í„° {total_batches}ê°œ ë°°ì¹˜ ì €ì¥ ì™„ë£Œ ({total_records}ê±´)")

    # ------------------------------------------------------------------
    # âœ… 3ï¸âƒ£ Fetch + Load í†µí•© ì‹¤í–‰
    # ------------------------------------------------------------------
    def fetch_and_load(self, **kwargs):
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        - API í˜¸ì¶œ(fetch)
        - ë°°ì¹˜ ë‹¨ìœ„ JSONL ì €ì¥(load)
        """

        self.log.info(f"ğŸš€ í€ë”ë©˜í„¸ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ({self.exchange_code}, {self.trd_dt})")

        try:
            records, meta = self.fetch(**kwargs)
            if not records:
                return {
                    "exchange_code": self.exchange_code,
                    "data_domain": self.data_domain,
                    "trd_dt": self.trd_dt,
                    "status": "skipped",
                    "record_count": 0,
                }

            kwargs["meta"] = meta
            self.load(records, **kwargs)
            status = "success"
        except Exception as e:
            self.log.error(f"âŒ í€ë”ë©˜í„¸ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            status = "failed"
            records = []

        return {
            "exchange_code": self.exchange_code,
            "data_domain": self.data_domain,
            "trd_dt": self.trd_dt,
            "status": status,
            "record_count": len(records),
        }
        #
        #
        # records, meta = self.fetch(**kwargs)
        # if not records:
        #     self.log.warning("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì ì¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        #     return
        #
        # kwargs['meta'] = meta
        # self.load(records, **kwargs)
        self.log.info(f"ğŸ¯ í€ë”ë©˜í„¸ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ ({self.exchange_code}, {self.trd_dt})")
