from datetime import datetime
from airflow import DAG
from airflow.models import Variable
from airflow.providers.standard.operators.empty import EmptyOperator
from airflow.providers.standard.operators.trigger_dagrun import TriggerDagRunOperator
from airflow.sdk import TaskGroup
from airflow.task.trigger_rule import TriggerRule

from plugins.config.constants import DOMAIN_GROUPS, VENDORS
from plugins.operators.lake_operator import LakeOperator
from plugins.pipelines.lake.equity.symbol_list_pipeline import SymbolListPipeline
from plugins.pipelines.lake.equity.exchange_detail_pipeline import ExchangeDetailPipeline
from plugins.config import constants as C
from plugins.validators.lake_data_validator import LakeDataValidator
from plugins.validators.lake.equity.exchange_detail_validator import ExchangeDetailValidator
import json


# âœ… Warehouseì—ì„œ êµ­ê°€-ê±°ëž˜ì†Œ ë§¤í•‘ ì½ê¸°
def _load_country_exchange_map_from_warehouse() -> dict:
    wh_root = C.DATA_WAREHOUSE_ROOT / "exchange"
    meta_files = sorted(wh_root.glob("trd_dt=*/_build_meta.json"), reverse=True)
    if not meta_files:
        raise FileNotFoundError(f"âŒ exchange_master ë©”íƒ€íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {wh_root}")

    latest_meta_path = meta_files[0]
    with open(latest_meta_path, "r", encoding="utf-8") as f:
        meta = json.load(f)

    mapping = meta.get("country_exchange_map", {})
    print(f"ðŸ“˜ ìµœì‹  exchange_master ìŠ¤ëƒ…ìƒ·: {latest_meta_path}")
    print(f"ðŸ“Š êµ­ê°€-ê±°ëž˜ì†Œ ë§¤í•‘ ë¡œë“œ ì™„ë£Œ (ì´ {len(mapping)}ê°œêµ­)")
    return mapping


# âœ… ì‹¬ë³¼ ìˆ˜ì§‘ íƒœìŠ¤í¬ ìƒì„±
def _build_symbol_tasks_for_country(dag, country_code: str, exchanges: list):
    symbol_tasks = {}
    print(f"ðŸŒ [{country_code}] ê±°ëž˜ì†Œ ìˆ˜ì§‘ ëŒ€ìƒ: {len(exchanges)}ê°œ â†’ {exchanges}")

    for exchange_code in exchanges:
        fetch_task = LakeOperator(
            task_id=f"{country_code}_{exchange_code}_fetch_symbol_list",
            pipeline_cls=SymbolListPipeline,
            method_name="fetch_and_load",
            op_kwargs={
                "exchange_code": exchange_code,
                "domain": C.DATA_DOMAINS["symbol_list"],
                "domain_group": C.DOMAIN_GROUPS["equity"],
                "trd_dt": "{{ data_interval_end | ds }}",
                "allow_empty": False,
            },
            dag=dag,
        )

        validate_task = LakeOperator(
            task_id=f"{country_code}_{exchange_code}_validate_symbol_list",
            pipeline_cls=LakeDataValidator,
            method_name="validate",
            op_kwargs={
                "exchange_code": exchange_code,
                "trd_dt": "{{ data_interval_end | ds }}",
                "domain": C.DATA_DOMAINS["symbol_list"],
                "domain_group": C.DOMAIN_GROUPS["equity"],
                "vendor": C.VENDORS["eodhd"],
            },
            dag=dag,
        )

        fetch_task >> validate_task
        symbol_tasks[exchange_code] = validate_task

    return symbol_tasks


# âœ… íœ´ìž¥ì¼ ìˆ˜ì§‘ íƒœìŠ¤í¬ ìƒì„±
def _build_exchange_detail_tasks_for_country(dag, country_code: str, exchanges: list):
    detail_tasks = {}
    print(f"ðŸ–ï¸ [{country_code}] ìƒì„¸ì •ë³´ ìˆ˜ì§‘ ëŒ€ìƒ: {len(exchanges)}ê°œ â†’ {exchanges}")

    for exchange_code in exchanges:
        fetch_task = LakeOperator(
            task_id=f"{country_code}_{exchange_code}_fetch_exchange_detail",
            pipeline_cls=ExchangeDetailPipeline,
            method_name="fetch_and_load",
            op_kwargs={
                "exchange_code": exchange_code,
                "domain": C.DATA_DOMAINS["exchange_detail"],
                "domain_group": C.DOMAIN_GROUPS["equity"],
                "trd_dt": "{{ data_interval_end | ds }}",
                "allow_empty": True,
            },
            dag=dag,
        )

        validate_task = LakeOperator(
            task_id=f"{country_code}_{exchange_code}_validate_exchange_detail",
            pipeline_cls=ExchangeDetailValidator,
            method_name="validate",
            op_kwargs={
                "exchange_code": exchange_code,
                "trd_dt": "{{ data_interval_end | ds }}",
                "domain": C.DATA_DOMAINS["exchange_detail"],
                "domain_group": C.DOMAIN_GROUPS["equity"],
                "vendor": C.VENDORS["eodhd"],
            },
            dag=dag,
        )

        fetch_task >> validate_task
        detail_tasks[exchange_code] = validate_task

    return detail_tasks


# =========================================================
# DAG ì •ì˜
# =========================================================
with DAG(
        dag_id="exchange_metadata_dag",
        description="Collect & validate exchange metadata, then trigger asset_master master build",
        start_date=datetime(2025, 10, 15),
        schedule="0 19 * * 1-5",  # í‰ì¼ KST 04ì‹œ
        catchup=False,
        max_active_runs=1,
        tags=["EODHD", "metadata", "exchange detail", "holiday"],
) as dag:
    start_task = EmptyOperator(task_id="start_pipeline")
    end_task = EmptyOperator(task_id="end_pipeline")

    # âœ… 1ï¸âƒ£ êµ­ê°€-ê±°ëž˜ì†Œ ë§¤í•‘ ë¡œë“œ (ê¸°ì¡´ ë™ì¼)
    try:
        country_exchange_map = _load_country_exchange_map_from_warehouse()
    except FileNotFoundError:
        print("âš ï¸ exchange_master ë©”íƒ€íŒŒì¼ ì—†ìŒ â†’ ê¸°ë³¸ê°’ ì‚¬ìš©")
        country_exchange_map = {"KOR": ["KO", "KQ"], "USA": ["US"]}

    active_countries = Variable.get("master_countries", default_var=["USA", "KOR"], deserialize_json=True)
    filtered_map = {c: country_exchange_map.get(c, []) for c in active_countries if country_exchange_map.get(c)}

    all_symbol_tasks = {}

    # âœ… 2ï¸âƒ£ êµ­ê°€ë³„ ì‹¬ë³¼ ìˆ˜ì§‘
    for country, exchanges in filtered_map.items():
        symbol_tasks = _build_symbol_tasks_for_country(dag, country, exchanges)
        all_symbol_tasks[country] = symbol_tasks

        # ì‹¬ë³¼ ê²€ì¦ ì™„ë£Œ í›„ â†’ asset_master ë¹Œë“œ íŠ¸ë¦¬ê±°
        with TaskGroup(group_id=f"group_trigger_master_{country}", dag=dag):
            trigger_asset_master = TriggerDagRunOperator(
                task_id=f"trigger_asset_master_{country}",
                trigger_dag_id="asset_master_dag",
                trigger_rule=TriggerRule.ALL_SUCCESS,
                conf={
                    "trigger_source": "symbol_list_validation",
                    "country_code": country,
                    "domain_group": DOMAIN_GROUPS['equity'],
                    "trd_dt": "{{ data_interval_end | ds }}",
                    "vendor": VENDORS['eodhd'],
                },
                reset_dag_run=True,
                wait_for_completion=False,
                dag=dag,
            )

            for val_task in symbol_tasks.values():
                val_task >> trigger_asset_master

    # âœ… 3ï¸âƒ£ íœ´ìž¥ì¼ ìˆ˜ì§‘ (ê¸°ì¡´ ë™ì¼)
    all_exchange_detail_tasks = {}
    for country, exchanges in filtered_map.items():
        exchange_detail_tasks = _build_exchange_detail_tasks_for_country(dag, country, exchanges)
        all_exchange_detail_tasks[country] = exchange_detail_tasks

        for val_task in all_symbol_tasks.get(country, {}).values():
            for h_val in exchange_detail_tasks.values():
                val_task >> h_val

    # âœ… 4ï¸âƒ£ ëª¨ë“  êµ­ê°€ì˜ exchange_detail ê²€ì¦ ì™„ë£Œ í›„ â†’ Warehouse DAG íŠ¸ë¦¬ê±°
    trigger_exchange_warehouse = TriggerDagRunOperator(
        task_id="trigger_exchange_warehouse_dag",
        trigger_dag_id="build_exchange_warehouse_dag",
        trigger_rule=TriggerRule.ALL_SUCCESS,
        conf={
            "trigger_source": "exchange_detail_validation",
            "domain_group": DOMAIN_GROUPS['equity'],
            "trd_dt": "{{ data_interval_end | ds }}",
            "vendor": VENDORS['eodhd'],
        },
        reset_dag_run=True,
        wait_for_completion=False,
        dag=dag,
    )

    # âœ… ëª¨ë“  exchange_detail ê²€ì¦ì´ ëë‚˜ë©´ Warehouse íŠ¸ë¦¬ê±°
    for country, tasks in all_exchange_detail_tasks.items():
        for h_val in tasks.values():
            h_val >> trigger_exchange_warehouse

    trigger_exchange_warehouse >> end_task
    start_task >> [v for c in all_symbol_tasks.values() for v in c.values()]